{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danto\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danto\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class Food101Dataset(Dataset):\n",
    "    def __init__(self, data_dir, train_txt_path, test_txt_path, val_split_ratio=0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.train_txt_path = train_txt_path\n",
    "        self.test_txt_path = test_txt_path\n",
    "        self.val_split_ratio = val_split_ratio\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.train_data, self.val_data, self.test_data, self.label_to_int = self._load_data(train_txt_path, test_txt_path)\n",
    "\n",
    "    def _load_data(self, train_txt_path, test_txt_path):\n",
    "        train_data = []\n",
    "        test_data = []\n",
    "\n",
    "        label_to_int = {}\n",
    "        int_label = 0\n",
    "\n",
    "        with open(os.path.join(self.data_dir, train_txt_path), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            filename = line.strip() + '.jpg'\n",
    "            label = filename.split('/')[0]\n",
    "            if label not in label_to_int:\n",
    "                label_to_int[label] = int_label\n",
    "                int_label += 1\n",
    "            image_path = os.path.join(self.data_dir, 'images', filename)\n",
    "            train_data.append((image_path, label))\n",
    "\n",
    "        with open(os.path.join(self.data_dir, test_txt_path), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            filename = line.strip() + '.jpg'\n",
    "            label = filename.split('/')[0]\n",
    "            image_path = os.path.join(self.data_dir, 'images', filename)\n",
    "            test_data.append((image_path, label))\n",
    "\n",
    "        # Split train_data into train and validation sets using train_test_split\n",
    "        train_data, val_data = train_test_split(train_data, test_size=self.val_split_ratio, random_state=42)\n",
    "\n",
    "        return train_data, val_data, test_data, label_to_int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data) + len(self.val_data) + len(self.test_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.train_data):\n",
    "            data_source = self.train_data\n",
    "        elif idx < len(self.train_data) + len(self.val_data):\n",
    "            data_source = self.val_data\n",
    "            idx -= len(self.train_data)\n",
    "        else:\n",
    "            data_source = self.test_data\n",
    "            idx -= (len(self.train_data) + len(self.val_data))\n",
    "\n",
    "        image_path, label = data_source[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Convert label to integer using label_to_int mapping\n",
    "        label = torch.tensor(self.label_to_int[label], dtype=torch.int64)\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'label': label,\n",
    "        }\n",
    "\n",
    "    def get_splits(self):\n",
    "        train_subset = Subset(self, list(range(len(self.train_data))))\n",
    "        val_subset = Subset(self, list(range(len(self.train_data), len(self.train_data) + len(self.val_data))))\n",
    "        test_subset = Subset(self, list(range(len(self.train_data) + len(self.val_data), len(self.train_data) + len(self.val_data) + len(self.test_data))))\n",
    "        return train_subset, val_subset, test_subset\n",
    "    \n",
    "class Config:\n",
    "    num_classes = 101\n",
    "    learning_rate = 1e-4\n",
    "    num_epochs = 256\n",
    "    batch_size = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the pre-trained ViT model\n",
    "model = models.vit_b_16(pretrained=True)\n",
    "\n",
    "in_features = model.heads.head.in_features\n",
    "classifier = nn.Linear(in_features=in_features, out_features=Config.num_classes)\n",
    "model.heads.head = classifier\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.heads.head.weight.requires_grad = True\n",
    "model.heads.head.bias.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "data_handler = Food101Dataset(data_dir='food101', train_txt_path='meta/train.txt', test_txt_path='meta/test.txt')\n",
    "\n",
    "train_data, val_data, test_data = data_handler.get_splits()\n",
    "\n",
    "# Create data loaders using the batch_size from the Config class\n",
    "train_loader = DataLoader(train_data, batch_size=Config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=Config.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=Config.batch_size, shuffle=False)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=Config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 3.3518: 100%|██████████| 474/474 [07:34<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/256] - Loss: 3.8601 - Validation Loss: 3.2599 - Validation Accuracy: 0.3630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 2.6555: 100%|██████████| 474/474 [07:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/256] - Loss: 2.9163 - Validation Loss: 2.6806 - Validation Accuracy: 0.4314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 2.6231: 100%|██████████| 474/474 [07:51<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/256] - Loss: 2.4982 - Validation Loss: 2.4002 - Validation Accuracy: 0.4692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 2.1252: 100%|██████████| 474/474 [07:39<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/256] - Loss: 2.2671 - Validation Loss: 2.2219 - Validation Accuracy: 0.4933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.9708: 100%|██████████| 474/474 [07:43<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/256] - Loss: 2.1144 - Validation Loss: 2.0989 - Validation Accuracy: 0.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 2.1129: 100%|██████████| 474/474 [07:35<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/256] - Loss: 2.0065 - Validation Loss: 2.0137 - Validation Accuracy: 0.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.5661: 100%|██████████| 474/474 [07:47<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/256] - Loss: 1.9257 - Validation Loss: 1.9511 - Validation Accuracy: 0.5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.7125: 100%|██████████| 474/474 [07:42<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/256] - Loss: 1.8568 - Validation Loss: 1.8894 - Validation Accuracy: 0.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 2.0777: 100%|██████████| 474/474 [07:37<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/256] - Loss: 1.8014 - Validation Loss: 1.8444 - Validation Accuracy: 0.5516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.8777: 100%|██████████| 474/474 [07:43<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/256] - Loss: 1.7597 - Validation Loss: 1.8043 - Validation Accuracy: 0.5570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3515: 100%|██████████| 474/474 [07:45<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/256] - Loss: 1.7153 - Validation Loss: 1.7706 - Validation Accuracy: 0.5622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.7074: 100%|██████████| 474/474 [07:45<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/256] - Loss: 1.6806 - Validation Loss: 1.7392 - Validation Accuracy: 0.5682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 2.0426: 100%|██████████| 474/474 [07:53<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/256] - Loss: 1.6490 - Validation Loss: 1.7225 - Validation Accuracy: 0.5710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.2076: 100%|██████████| 474/474 [07:36<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/256] - Loss: 1.6199 - Validation Loss: 1.7003 - Validation Accuracy: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.7592: 100%|██████████| 474/474 [07:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/256] - Loss: 1.5978 - Validation Loss: 1.6788 - Validation Accuracy: 0.5825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.8603: 100%|██████████| 474/474 [07:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/256] - Loss: 1.5709 - Validation Loss: 1.6548 - Validation Accuracy: 0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.4865: 100%|██████████| 474/474 [07:41<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/256] - Loss: 1.5513 - Validation Loss: 1.6354 - Validation Accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3304: 100%|██████████| 474/474 [07:44<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/256] - Loss: 1.5324 - Validation Loss: 1.6302 - Validation Accuracy: 0.5888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.5023: 100%|██████████| 474/474 [07:50<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/256] - Loss: 1.5159 - Validation Loss: 1.6166 - Validation Accuracy: 0.5967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.2919: 100%|██████████| 474/474 [07:35<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/256] - Loss: 1.4985 - Validation Loss: 1.5965 - Validation Accuracy: 0.5974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.6231: 100%|██████████| 474/474 [07:54<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/256] - Loss: 1.4823 - Validation Loss: 1.5882 - Validation Accuracy: 0.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.0847: 100%|██████████| 474/474 [07:44<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/256] - Loss: 1.4672 - Validation Loss: 1.5816 - Validation Accuracy: 0.5970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.8866: 100%|██████████| 474/474 [07:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/256] - Loss: 1.4524 - Validation Loss: 1.5634 - Validation Accuracy: 0.6030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.4973: 100%|██████████| 474/474 [07:49<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/256] - Loss: 1.4385 - Validation Loss: 1.5612 - Validation Accuracy: 0.6030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3206: 100%|██████████| 474/474 [07:42<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/256] - Loss: 1.4296 - Validation Loss: 1.5486 - Validation Accuracy: 0.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3887: 100%|██████████| 474/474 [07:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/256] - Loss: 1.4142 - Validation Loss: 1.5326 - Validation Accuracy: 0.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3913: 100%|██████████| 474/474 [07:38<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/256] - Loss: 1.4046 - Validation Loss: 1.5250 - Validation Accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.5247: 100%|██████████| 474/474 [07:35<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/256] - Loss: 1.3921 - Validation Loss: 1.5192 - Validation Accuracy: 0.6157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3588: 100%|██████████| 474/474 [07:43<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/256] - Loss: 1.3828 - Validation Loss: 1.5149 - Validation Accuracy: 0.6141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.1048: 100%|██████████| 474/474 [07:41<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/256] - Loss: 1.3741 - Validation Loss: 1.5073 - Validation Accuracy: 0.6145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.2477: 100%|██████████| 474/474 [07:42<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/256] - Loss: 1.3646 - Validation Loss: 1.4985 - Validation Accuracy: 0.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.0374: 100%|██████████| 474/474 [07:19<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/256] - Loss: 1.3532 - Validation Loss: 1.4938 - Validation Accuracy: 0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3463: 100%|██████████| 474/474 [07:29<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/256] - Loss: 1.3474 - Validation Loss: 1.4909 - Validation Accuracy: 0.6193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3514: 100%|██████████| 474/474 [07:34<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/256] - Loss: 1.3398 - Validation Loss: 1.4862 - Validation Accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.2551: 100%|██████████| 474/474 [07:30<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/256] - Loss: 1.3277 - Validation Loss: 1.4777 - Validation Accuracy: 0.6244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.4690: 100%|██████████| 474/474 [07:23<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/256] - Loss: 1.3220 - Validation Loss: 1.4782 - Validation Accuracy: 0.6236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 0.9580: 100%|██████████| 474/474 [07:29<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/256] - Loss: 1.3129 - Validation Loss: 1.4636 - Validation Accuracy: 0.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.5459: 100%|██████████| 474/474 [07:28<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/256] - Loss: 1.3073 - Validation Loss: 1.4571 - Validation Accuracy: 0.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.0964: 100%|██████████| 474/474 [57:28<00:00,  7.28s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/256] - Loss: 1.3019 - Validation Loss: 1.4579 - Validation Accuracy: 0.6275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.3492: 100%|██████████| 474/474 [07:22<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/256] - Loss: 1.2953 - Validation Loss: 1.4510 - Validation Accuracy: 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.0958: 100%|██████████| 474/474 [07:32<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/256] - Loss: 1.2859 - Validation Loss: 1.4406 - Validation Accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.4903: 100%|██████████| 474/474 [07:25<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/256] - Loss: 1.2789 - Validation Loss: 1.4480 - Validation Accuracy: 0.6290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 473/474, Loss: 1.4293: 100%|██████████| 474/474 [07:34<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/256] - Loss: 1.2751 - Validation Loss: 1.4485 - Validation Accuracy: 0.6330\n",
      "Validation loss has increased twice in a row. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Initialize a deque to keep track of the last two validation accuracies\n",
    "val_loss_history = deque(maxlen=2)\n",
    "\n",
    "# Define a variable to track the number of consecutive times validation accuracy drops\n",
    "consecutive_drops = 0\n",
    "\n",
    "for epoch in range(Config.num_epochs):\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, batch in progress_bar:\n",
    "        # Retrieve features and labels from the current batch\n",
    "        features = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f\"Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    progress_bar.close()\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            features = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(features)\n",
    "\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_total_loss += val_loss.item()\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "\n",
    "    average_val_loss = val_total_loss / len(val_loader)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f'Epoch [{epoch + 1}/{Config.num_epochs}] - Loss: {average_loss:.4f} - Validation Loss: {average_val_loss:.4f} - Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Append the validation loss to the history\n",
    "    val_loss_history.append(average_val_loss)\n",
    "\n",
    "    # Check if validation loss has increased twice in a row\n",
    "    if len(val_loss_history) == 2 and val_loss_history[0] < val_loss_history[1]:\n",
    "        consecutive_increases += 1\n",
    "        if consecutive_increases >= 2:\n",
    "            print('Validation loss has increased twice in a row. Stopping training.')\n",
    "            break\n",
    "    else:\n",
    "        consecutive_increases = 0  # Reset counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'food101_vit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.2133 - Test Accuracy: 0.6863\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.43      0.35      0.39       250\n",
      "     Class 1       0.63      0.74      0.68       250\n",
      "     Class 2       0.73      0.67      0.70       250\n",
      "     Class 3       0.71      0.72      0.72       250\n",
      "     Class 4       0.55      0.57      0.56       250\n",
      "     Class 5       0.56      0.60      0.58       250\n",
      "     Class 6       0.78      0.78      0.78       250\n",
      "     Class 7       0.81      0.83      0.82       250\n",
      "     Class 8       0.44      0.44      0.44       250\n",
      "     Class 9       0.61      0.63      0.62       250\n",
      "    Class 10       0.60      0.56      0.58       250\n",
      "    Class 11       0.69      0.76      0.73       250\n",
      "    Class 12       0.63      0.70      0.66       250\n",
      "    Class 13       0.65      0.70      0.67       250\n",
      "    Class 14       0.69      0.66      0.67       250\n",
      "    Class 15       0.52      0.46      0.49       250\n",
      "    Class 16       0.63      0.54      0.58       250\n",
      "    Class 17       0.69      0.66      0.68       250\n",
      "    Class 18       0.56      0.53      0.55       250\n",
      "    Class 19       0.61      0.68      0.65       250\n",
      "    Class 20       0.79      0.78      0.78       250\n",
      "    Class 21       0.59      0.64      0.61       250\n",
      "    Class 22       0.44      0.50      0.47       250\n",
      "    Class 23       0.76      0.76      0.76       250\n",
      "    Class 24       0.75      0.84      0.79       250\n",
      "    Class 25       0.72      0.73      0.73       250\n",
      "    Class 26       0.52      0.47      0.49       250\n",
      "    Class 27       0.80      0.84      0.82       250\n",
      "    Class 28       0.73      0.75      0.74       250\n",
      "    Class 29       0.79      0.86      0.82       250\n",
      "    Class 30       0.78      0.81      0.79       250\n",
      "    Class 31       0.77      0.79      0.78       250\n",
      "    Class 32       0.84      0.85      0.85       250\n",
      "    Class 33       0.98      0.98      0.98       250\n",
      "    Class 34       0.79      0.76      0.77       250\n",
      "    Class 35       0.78      0.73      0.76       250\n",
      "    Class 36       0.59      0.53      0.56       250\n",
      "    Class 37       0.49      0.53      0.51       250\n",
      "    Class 38       0.74      0.76      0.75       250\n",
      "    Class 39       0.38      0.40      0.39       250\n",
      "    Class 40       0.75      0.85      0.80       250\n",
      "    Class 41       0.71      0.74      0.72       250\n",
      "    Class 42       0.55      0.59      0.57       250\n",
      "    Class 43       0.74      0.70      0.72       250\n",
      "    Class 44       0.76      0.75      0.75       250\n",
      "    Class 45       0.84      0.83      0.83       250\n",
      "    Class 46       0.64      0.65      0.64       250\n",
      "    Class 47       0.59      0.50      0.55       250\n",
      "    Class 48       0.76      0.73      0.74       250\n",
      "    Class 49       0.51      0.54      0.52       250\n",
      "    Class 50       0.53      0.50      0.51       250\n",
      "    Class 51       0.84      0.90      0.87       250\n",
      "    Class 52       0.69      0.72      0.71       250\n",
      "    Class 53       0.70      0.76      0.73       250\n",
      "    Class 54       0.88      0.90      0.89       250\n",
      "    Class 55       0.82      0.86      0.84       250\n",
      "    Class 56       0.50      0.41      0.45       250\n",
      "    Class 57       0.61      0.54      0.57       250\n",
      "    Class 58       0.73      0.64      0.68       250\n",
      "    Class 59       0.55      0.53      0.54       250\n",
      "    Class 60       0.80      0.79      0.79       250\n",
      "    Class 61       0.77      0.72      0.74       250\n",
      "    Class 62       0.66      0.65      0.66       250\n",
      "    Class 63       0.92      0.92      0.92       250\n",
      "    Class 64       0.87      0.89      0.88       250\n",
      "    Class 65       0.84      0.82      0.83       250\n",
      "    Class 66       0.60      0.60      0.60       250\n",
      "    Class 67       0.57      0.49      0.53       250\n",
      "    Class 68       0.83      0.82      0.82       250\n",
      "    Class 69       0.86      0.91      0.88       250\n",
      "    Class 70       0.80      0.85      0.82       250\n",
      "    Class 71       0.75      0.74      0.74       250\n",
      "    Class 72       0.70      0.74      0.72       250\n",
      "    Class 73       0.58      0.67      0.62       250\n",
      "    Class 74       0.70      0.70      0.70       250\n",
      "    Class 75       0.83      0.88      0.85       250\n",
      "    Class 76       0.80      0.88      0.83       250\n",
      "    Class 77       0.48      0.31      0.38       250\n",
      "    Class 78       0.74      0.74      0.74       250\n",
      "    Class 79       0.65      0.78      0.71       250\n",
      "    Class 80       0.65      0.62      0.63       250\n",
      "    Class 81       0.76      0.74      0.75       250\n",
      "    Class 82       0.52      0.46      0.49       250\n",
      "    Class 83       0.81      0.77      0.79       250\n",
      "    Class 84       0.59      0.55      0.57       250\n",
      "    Class 85       0.65      0.67      0.66       250\n",
      "    Class 86       0.76      0.86      0.81       250\n",
      "    Class 87       0.48      0.50      0.49       250\n",
      "    Class 88       0.79      0.83      0.81       250\n",
      "    Class 89       0.56      0.62      0.59       250\n",
      "    Class 90       0.81      0.84      0.82       250\n",
      "    Class 91       0.87      0.90      0.88       250\n",
      "    Class 92       0.70      0.70      0.70       250\n",
      "    Class 93       0.48      0.41      0.44       250\n",
      "    Class 94       0.69      0.74      0.71       250\n",
      "    Class 95       0.74      0.65      0.69       250\n",
      "    Class 96       0.58      0.60      0.59       250\n",
      "    Class 97       0.72      0.69      0.70       250\n",
      "    Class 98       0.65      0.56      0.60       250\n",
      "    Class 99       0.49      0.41      0.45       250\n",
      "   Class 100       0.76      0.79      0.78       250\n",
      "\n",
      "    accuracy                           0.69     25250\n",
      "   macro avg       0.68      0.69      0.68     25250\n",
      "weighted avg       0.68      0.69      0.68     25250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def evaluate_on_test_data(model, criterion, num_classes, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            features = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(features)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Assuming your model returns class probabilities, apply softmax\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "    \n",
    "    average_loss = total_loss / len(test_loader)\n",
    "\n",
    "    # Compute the classification report\n",
    "    classification_rep = classification_report(all_labels, all_predictions, target_names=[f'Class {i}' for i in range(num_classes)])\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    print(f'Test Loss: {average_loss:.4f} - Test Accuracy: {accuracy:.4f}')\n",
    "    print('Classification Report:\\n', classification_rep)\n",
    "\n",
    "evaluate_on_test_data(model, criterion, Config.num_classes, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
